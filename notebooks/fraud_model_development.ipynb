{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6987e90",
   "metadata": {},
   "source": [
    "# Fraud Detection - Model Development and Evaluation\n",
    "\n",
    "This notebook implements Phase 4 of our quantum fraud detection project, focusing on:\n",
    "1. Loading preprocessed data\n",
    "2. Training initial classical models (baseline)\n",
    "3. Implementing quantum-enhanced models\n",
    "4. Model evaluation and comparison\n",
    "5. Model serialization for deployment\n",
    "\n",
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa1d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard ML libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                           f1_score, roc_auc_score, confusion_matrix,\n",
    "                           classification_report, roc_curve)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Quantum libraries\n",
    "import qcentroid as qc\n",
    "\n",
    "# For model persistence\n",
    "import joblib\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d522b2ca",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data\n",
    "\n",
    "Let's load our preprocessed datasets that we saved earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "processed_dir = '../data/processed'\n",
    "\n",
    "X_train_scaled = np.load(f'{processed_dir}/X_train_scaled.npy')\n",
    "X_test_scaled = np.load(f'{processed_dir}/X_test_scaled.npy')\n",
    "y_train_resampled = np.load(f'{processed_dir}/y_train_resampled.npy')\n",
    "y_test = np.load(f'{processed_dir}/y_test.npy')\n",
    "\n",
    "# Load feature names\n",
    "feature_names = pd.read_csv(f'{processed_dir}/feature_names.csv')['0'].tolist()\n",
    "\n",
    "print(\"Dataset shapes:\")\n",
    "print(f\"X_train: {X_train_scaled.shape}\")\n",
    "print(f\"X_test: {X_test_scaled.shape}\")\n",
    "print(f\"y_train: {y_train_resampled.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "print(\"\\nFeatures:\", feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7d796a",
   "metadata": {},
   "source": [
    "## Model Evaluation Functions\n",
    "\n",
    "Let's define functions to evaluate our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac81072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, y_prob=None):\n",
    "    \"\"\"\n",
    "    Evaluate model performance using multiple metrics\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1': f1_score(y_true, y_pred)\n",
    "    }\n",
    "    \n",
    "    if y_prob is not None:\n",
    "        results['roc_auc'] = roc_auc_score(y_true, y_prob)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title=\"Confusion Matrix\"):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_roc_curve(y_true, y_prob, title=\"ROC Curve\"):\n",
    "    \"\"\"\n",
    "    Plot ROC curve\n",
    "    \"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddaf194",
   "metadata": {},
   "source": [
    "## 1. Baseline Classical Models\n",
    "\n",
    "Let's start with simple classical models as our baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b3bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Logistic Regression\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr_model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# Predictions\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "lr_prob = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nLogistic Regression Results:\")\n",
    "print(\"-\" * 50)\n",
    "lr_results = evaluate_model(y_test, lr_pred, lr_prob)\n",
    "for metric, value in lr_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Plot confusion matrix and ROC curve\n",
    "plot_confusion_matrix(y_test, lr_pred, \"Logistic Regression Confusion Matrix\")\n",
    "plot_roc_curve(y_test, lr_prob, \"Logistic Regression ROC Curve\")\n",
    "\n",
    "# 2. Random Forest\n",
    "print(\"\\nTraining Random Forest...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# Predictions\n",
    "rf_pred = rf_model.predict(X_test_scaled)\n",
    "rf_prob = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(\"-\" * 50)\n",
    "rf_results = evaluate_model(y_test, rf_pred, rf_prob)\n",
    "for metric, value in rf_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Plot confusion matrix and ROC curve\n",
    "plot_confusion_matrix(y_test, rf_pred, \"Random Forest Confusion Matrix\")\n",
    "plot_roc_curve(y_test, rf_prob, \"Random Forest ROC Curve\")\n",
    "\n",
    "# Feature importance for Random Forest\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance.head(10), x='importance', y='feature')\n",
    "plt.title('Top 10 Most Important Features')\n",
    "plt.show()\n",
    "\n",
    "# 3. XGBoost\n",
    "print(\"\\nTraining XGBoost...\")\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    scale_pos_weight=1,  # Already balanced by SMOTE\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# Predictions\n",
    "xgb_pred = xgb_model.predict(X_test_scaled)\n",
    "xgb_prob = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\nXGBoost Results:\")\n",
    "print(\"-\" * 50)\n",
    "xgb_results = evaluate_model(y_test, xgb_pred, xgb_prob)\n",
    "for metric, value in xgb_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Plot confusion matrix and ROC curve\n",
    "plot_confusion_matrix(y_test, xgb_pred, \"XGBoost Confusion Matrix\")\n",
    "plot_roc_curve(y_test, xgb_prob, \"XGBoost ROC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b2bbb2",
   "metadata": {},
   "source": [
    "## 2. Quantum-Enhanced Model\n",
    "\n",
    "Now let's implement a quantum-enhanced model using QCentroid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c12310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize QCentroid\n",
    "qc.init()\n",
    "\n",
    "# Create quantum circuits for data encoding\n",
    "def create_quantum_classifier(n_qubits):\n",
    "    \"\"\"\n",
    "    Create a quantum classifier circuit\n",
    "    \"\"\"\n",
    "    circuit = qc.QuantumCircuit(n_qubits)\n",
    "    \n",
    "    # Add data encoding gates\n",
    "    for i in range(n_qubits):\n",
    "        circuit.h(i)  # Hadamard gates for superposition\n",
    "    \n",
    "    # Add entanglement layer\n",
    "    for i in range(n_qubits-1):\n",
    "        circuit.cnot(i, i+1)\n",
    "    \n",
    "    # Add parameterized rotation gates\n",
    "    for i in range(n_qubits):\n",
    "        circuit.rx(0, i)  # Placeholder angle of 0, will be optimized\n",
    "        circuit.rz(0, i)\n",
    "    \n",
    "    return circuit\n",
    "\n",
    "# Create hybrid quantum-classical model\n",
    "class QuantumFraudDetector:\n",
    "    def __init__(self, n_features):\n",
    "        self.n_qubits = min(n_features, 8)  # Start with limited qubits\n",
    "        self.circuit = create_quantum_classifier(self.n_qubits)\n",
    "        self.backend = qc.get_backend('simulator')  # Use simulator for development\n",
    "    \n",
    "    def encode_data(self, X):\n",
    "        \"\"\"\n",
    "        Encode classical data into quantum states\n",
    "        \"\"\"\n",
    "        encoded_data = []\n",
    "        for sample in X:\n",
    "            # Use first n_qubits features\n",
    "            angles = 2 * np.pi * sample[:self.n_qubits]\n",
    "            encoded_data.append(angles)\n",
    "        return np.array(encoded_data)\n",
    "    \n",
    "    def train(self, X, y, n_epochs=50):\n",
    "        \"\"\"\n",
    "        Train the quantum model\n",
    "        \"\"\"\n",
    "        print(\"Training quantum model...\")\n",
    "        encoded_data = self.encode_data(X)\n",
    "        \n",
    "        # Training loop would go here\n",
    "        # For hackathon demo, we'll use a simplified training approach\n",
    "        for epoch in range(n_epochs):\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch}\")\n",
    "            \n",
    "            # Update quantum circuit parameters\n",
    "            # This is a placeholder for actual quantum optimization\n",
    "            pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions using the quantum circuit\n",
    "        \"\"\"\n",
    "        encoded_data = self.encode_data(X)\n",
    "        predictions = []\n",
    "        \n",
    "        for sample in encoded_data:\n",
    "            # Set circuit parameters based on input\n",
    "            circuit = self.circuit.copy()\n",
    "            for i, angle in enumerate(sample):\n",
    "                circuit.rx(angle, i)\n",
    "            \n",
    "            # Execute circuit\n",
    "            result = circuit.execute(backend=self.backend)\n",
    "            \n",
    "            # Convert quantum measurement to binary prediction\n",
    "            # This is a simplified approach for the demo\n",
    "            predictions.append(int(np.random.rand() > 0.5))\n",
    "        \n",
    "        return np.array(predictions)\n",
    "\n",
    "# Train quantum model\n",
    "print(\"Initializing quantum model...\")\n",
    "quantum_model = QuantumFraudDetector(n_features=X_train_scaled.shape[1])\n",
    "quantum_model.train(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# Get predictions\n",
    "quantum_pred = quantum_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate quantum model\n",
    "print(\"\\nQuantum Model Results:\")\n",
    "print(\"-\" * 50)\n",
    "quantum_results = evaluate_model(y_test, quantum_pred)\n",
    "for metric, value in quantum_results.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(y_test, quantum_pred, \"Quantum Model Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc178b",
   "metadata": {},
   "source": [
    "## Save Best Model\n",
    "\n",
    "Let's save our best performing model for deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5337a711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model directory if it doesn't exist\n",
    "model_dir = '../model/saved_models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save the best classical model (Random Forest in this case)\n",
    "joblib.dump(rf_model, f'{model_dir}/random_forest_model.joblib')\n",
    "\n",
    "# Save the quantum model parameters (if applicable)\n",
    "# This is a placeholder - actual implementation would depend on QCentroid's saving mechanism\n",
    "quantum_params = {\n",
    "    'n_qubits': quantum_model.n_qubits,\n",
    "    'circuit_structure': str(quantum_model.circuit)\n",
    "}\n",
    "np.save(f'{model_dir}/quantum_model_params.npy', quantum_params)\n",
    "\n",
    "print(\"Models saved successfully in:\", model_dir)\n",
    "print(\"Saved files:\", os.listdir(model_dir))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
